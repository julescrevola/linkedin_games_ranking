import pandas as pd
import argparse

from linkedin_games_parser import parse_whatsapp_chat

# Path to input data
INPUT = "../data/input/_chat_fr.txt"
# Output CSV generated by the parser
PARSER_OUTPUT = "../data/output/games_leaderboard.csv"

# List of known games
GAMES = ["Tango", "Queens", "Mini Sudoku", "Zip"]


def run_parser():
    """Run the linkedin_games_parser.py script to update CSV."""
    try:
        df = parse_whatsapp_chat(INPUT)  # returns DataFrame with correct columns
        df.to_csv(PARSER_OUTPUT, index=False)
        return True
    except Exception as e:
        print(f"Error parsing chat: {e}")
        return False


def time_to_seconds(time_str):
    """Convert a time string mm:ss or hh:mm:ss to total seconds."""
    try:
        parts = [int(p) for p in time_str.strip().split(":")]
        if len(parts) == 2:
            return parts[0] * 60 + parts[1]
        elif len(parts) == 3:
            return parts[0] * 3600 + parts[1] * 60 + parts[2]
        else:
            return None
    except ValueError:
        return None


def compute_per_game_rankings(file_path, day=None):
    """
    Returns a dictionary of DataFrames, one per game, ranked from best (lowest time) to worst.
    Also includes average CEO percentage per player, ignoring NaN values.
    """
    df = pd.read_csv(file_path)

    # Filter by day if provided
    if day:
        df = df[df["date"] == day]

    # Convert play_time to seconds
    df["time_sec"] = df["play_time"].apply(time_to_seconds)

    # Convert CEO percentage to numeric
    df["ceo_percent"] = pd.to_numeric(df["ceo_percent"], errors="coerce")

    per_game_rankings = {}
    overall_best_sum = pd.DataFrame({"sender": df["sender"].unique()})

    for game in GAMES:
        game_df = df[df["game"].str.lower() == game.lower()].copy()
        if game_df.empty:
            continue

        # For each date, find the player(s) with the lowest time
        best_per_day = (
            game_df.loc[
                game_df.groupby("date")["time_sec"].idxmin(), ["date", "sender"]
            ]
            .groupby("sender")
            .size()
            .reset_index(name="num_best")
        )

        # Compute average CEO percentage per player
        ceo_avg = game_df.groupby("sender", as_index=False)["ceo_percent"].mean()

        # Compute avg times per player (if multiple plays, take the best time)
        avg_times = game_df.groupby("sender", as_index=False)["time_sec"].mean()

        # Compute min times per player (if multiple plays, take the best time)
        min_times = game_df.groupby("sender", as_index=False)["time_sec"].min()

        # Merge best times and CEO averages
        merged = (
            pd.merge(avg_times, ceo_avg, on="sender")
            .merge(min_times, on="sender", suffixes=("_avg", "_min"))
            .merge(best_per_day, on="sender", how="left")
            .fillna({"num_best": 0})
        )

        if day:
            # Sort by lowest time (best performance first)
            merged = merged.sort_values(by="time_sec_avg", ascending=True).reset_index(
                drop=True
            )
        else:
            # Sort by number of times best (highest first)
            merged = merged.sort_values(by="num_best", ascending=False).reset_index(
                drop=True
            )

        # Convert time back to mm:ss for nicer display
        merged["avg_play_time_mmss"] = merged["time_sec_avg"].apply(
            lambda x: f"{int(x // 60)}:{int(x % 60):02d}"
        )
        merged["min_play_time_mmss"] = merged["time_sec_min"].apply(
            lambda x: f"{int(x // 60)}:{int(x % 60):02d}"
        )
        # Round CEO percentage to 2 decimals
        merged["ceo_percent"] = merged["ceo_percent"].round(2)
        # Convert num_best to int
        merged["num_best"] = merged["num_best"].astype(int, errors="ignore")

        # Keep only relevant columns
        per_game_rankings[game] = merged[
            [
                "sender",
                "avg_play_time_mmss",
                "min_play_time_mmss",
                "ceo_percent",
                "num_best",
            ]
        ]

        # Add dataframe combining all times number of best times
        overall_best_sum = (
            overall_best_sum.merge(
                merged[["sender", "num_best"]], on="sender", how="left"
            )
            .fillna({"num_best": 0})
            .rename(columns={"num_best": f"num_best_{game}"})
        )

    # Sum num_best across all games for overall ranking
    overall_best_sum["num_best_total"] = (
        overall_best_sum[
            [
                f"num_best_{game}"
                for game in GAMES
                if f"num_best_{game}" in overall_best_sum.columns
            ]
        ]
        .sum(axis=1)
        .astype(int, errors="ignore")
    )
    overall_best_sum = (
        overall_best_sum[["sender", "num_best_total"]]
        .sort_values(by="num_best_total", ascending=False)
        .reset_index(drop=True)
    )

    # Add overall summary to the dictionary
    per_game_rankings["All"] = overall_best_sum

    return per_game_rankings


def main(day=None):
    if not run_parser():
        return

    per_game_rankings = compute_per_game_rankings(PARSER_OUTPUT, day=day)

    for game, df in per_game_rankings.items():
        print(f"\n=== {game} Rankings ===")
        print(df)
        df.to_csv(
            f"../data/output/{day if day is not None else 'overall'}_{game.lower().replace(' ', '_')}_rankings.csv",
            index=False,
        )


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Per-game mini leaderboard with CEO percentages"
    )
    parser.add_argument(
        "--day",
        type=str,
        help="Specific day (YYYY-MM-DD) to filter results, or omit for all-time",
    )
    args = parser.parse_args()

    main(day=args.day)
